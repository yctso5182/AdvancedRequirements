{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Object Classification from 3D-Point Cloud data\n",
    "\n",
    "In this tutorial, we are going to train (Hands-on) the PointNet on ModelNet40 PointCloud Dataset for object classification in 3D. \n",
    "\n",
    "All the theoretical intuitions are provided in the [Introduction Notebook](0-Introduction.ipynb)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### import required modules\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from dataloaders.ModelNetDataLoader import ModelNetDataLoader\n",
    "from utilities.data_manipulation import random_point_dropout, random_scale_point_cloud, shift_point_cloud  # The test function\n",
    "from utilities.activation import inplace_relu    # To save memory"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the following, we define the number of parameters and their values. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Args:\n",
    "    '''PARAMETERS'''\n",
    "    use_cpu =False\n",
    "    gpu='0'\n",
    "    batch_size = 24\n",
    "    model='pointnet_cls'\n",
    "    num_category = 40\n",
    "    epoch=200\n",
    "    learning_rate=0.001\n",
    "    num_point=1024\n",
    "    optimizer='Adam'\n",
    "    log_dir = 'runs'\n",
    "    decay_rate=1e-4\n",
    "    use_normals=False\n",
    "    process_data=False\n",
    "    use_uniform_sample=False\n",
    "\n",
    "args = Args()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the following block, we define the test function. We will use this function inside our training loop to validate and see the performance of our model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def test(model, loader, num_class=args.num_category):\n",
    "    mean_correct = []\n",
    "    class_acc = np.zeros((num_class, 3))\n",
    "    classifier = model.eval()\n",
    "\n",
    "    for j, (points, target) in tqdm(enumerate(loader), total=len(loader)):\n",
    "\n",
    "        if not args.use_cpu:\n",
    "            points, target = points.cuda(), target.cuda()\n",
    "\n",
    "        points = points.transpose(2, 1)\n",
    "        pred, _ = classifier(points)\n",
    "        pred_choice = pred.data.max(1)[1]\n",
    "\n",
    "        for cat in np.unique(target.cpu()):\n",
    "            classacc = pred_choice[target == cat].eq(target[target == cat].long().data).cpu().sum()\n",
    "            class_acc[cat, 0] += classacc.item() / float(points[target == cat].size()[0])\n",
    "            class_acc[cat, 1] += 1\n",
    "\n",
    "        correct = pred_choice.eq(target.long().data).cpu().sum()\n",
    "        mean_correct.append(correct.item() / float(points.size()[0]))\n",
    "\n",
    "    class_acc[:, 2] = class_acc[:, 0] / class_acc[:, 1]\n",
    "    class_acc = np.mean(class_acc[:, 2])\n",
    "    instance_acc = np.mean(mean_correct)\n",
    "\n",
    "    return instance_acc, class_acc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Verify if a Nvidia GPU is available for training the network. Check args.gpu value to define the available GPU in a cluster of GPUs."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the following, we will load the ModelNetX (X=10/40) Dataset from the disk. To download the dataset, follow the download and preparation instructions given in [Introduction Notebook](0-Introduction.ipynb). For this tutorial, we are using ModelNet40 having 40 classes. It is also possible to use ModelNet10 with ten object classes, a subgroup of the ModelNet40 dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### load the data from the hard disk\n",
    "data_path = '../data/modelnet40_normal_resampled/'\n",
    "\n",
    "train_dataset = ModelNetDataLoader(root=data_path, args=args,  split='train', process_data=args.process_data)\n",
    "test_dataset = ModelNetDataLoader(root=data_path, args=args, split='test', process_data=args.process_data)\n",
    "trainDataLoader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=10, drop_last=True)\n",
    "testDataLoader = torch.utils.data.DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=10)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the following we define the PointNet classification model. To visualize how the model looks like, check [Introduction Notebook](0-Introduction.ipynb)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_class = args.num_category    ### number of classes.\n",
    "from models.pointnet_cls import get_model, get_loss\n",
    "classifier = get_model(num_class, normal_channel=args.use_normals)\n",
    "criterion = get_loss()\n",
    "classifier.apply(inplace_relu)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the following, we define the model optimizer and we initialize the schedular."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if args.optimizer == 'Adam':\n",
    "    optimizer = torch.optim.Adam(\n",
    "        classifier.parameters(),\n",
    "        lr=args.learning_rate,\n",
    "        betas=(0.9, 0.999),\n",
    "        eps=1e-08,\n",
    "        weight_decay=args.decay_rate\n",
    "    )\n",
    "else:\n",
    "    optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.7)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the following, we define the path to save the best trained weights."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if not args.use_cpu:\n",
    "    classifier = classifier.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load('save_weights/best_model_classification.pth')\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    classifier.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print('Use pretrain model')\n",
    "except:\n",
    "    print('No existing model, starting training from scratch...')\n",
    "    start_epoch = 0\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the following block, we define and initialize the parameters for performance."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "global_epoch = 0\n",
    "global_step = 0\n",
    "best_instance_acc = 0.0\n",
    "best_class_acc = 0.0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### ***Following is the training loop.***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Start training...')\n",
    "for epoch in range(start_epoch, args.epoch):\n",
    "    print('Epoch %d (%d/%s):' % (global_epoch + 1, epoch + 1, args.epoch))\n",
    "    mean_correct = []\n",
    "    classifier = classifier.train()\n",
    "\n",
    "    scheduler.step()\n",
    "    for batch_id, (points, target) in tqdm(enumerate(trainDataLoader, 0), total=len(trainDataLoader), smoothing=0.9):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        points = points.data.numpy()\n",
    "        points = random_point_dropout(points)\n",
    "        points[:, :, 0:3] = random_scale_point_cloud(points[:, :, 0:3])\n",
    "        points[:, :, 0:3] = shift_point_cloud(points[:, :, 0:3])\n",
    "        points = torch.Tensor(points)\n",
    "        points = points.transpose(2, 1)\n",
    "\n",
    "        if not args.use_cpu:\n",
    "            points, target = points.cuda(), target.cuda()\n",
    "\n",
    "        pred, trans_feat = classifier(points)\n",
    "        loss = criterion(pred, target.long(), trans_feat)\n",
    "        pred_choice = pred.data.max(1)[1]\n",
    "\n",
    "        correct = pred_choice.eq(target.long().data).cpu().sum()\n",
    "        mean_correct.append(correct.item() / float(points.size()[0]))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        global_step += 1\n",
    "\n",
    "    train_instance_acc = np.mean(mean_correct)\n",
    "    print('Train Instance Accuracy: %f' % train_instance_acc)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        instance_acc, class_acc = test(classifier.eval(), testDataLoader, num_class=num_class)\n",
    "\n",
    "        if (instance_acc >= best_instance_acc):\n",
    "            best_instance_acc = instance_acc\n",
    "            best_epoch = epoch + 1\n",
    "\n",
    "        if (class_acc >= best_class_acc):\n",
    "            best_class_acc = class_acc\n",
    "        print('Test Instance Accuracy: %f, Class Accuracy: %f' % (instance_acc, class_acc))\n",
    "        print('Best Instance Accuracy: %f, Class Accuracy: %f' % (best_instance_acc, best_class_acc))\n",
    "\n",
    "        if (instance_acc >= best_instance_acc):\n",
    "            print('Save model...')\n",
    "            savepath = 'save_weights/' + 'best_model_classification.pth'\n",
    "            print('Saving at %s' % savepath)\n",
    "            state = {\n",
    "                'epoch': best_epoch,\n",
    "                'instance_acc': instance_acc,\n",
    "                'class_acc': class_acc,\n",
    "                'model_state_dict': classifier.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }\n",
    "            torch.save(state, savepath)\n",
    "        global_epoch += 1\n",
    "\n",
    "print('End of training...')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f50e1d202e66ca9d1bb86231cb6414771e783b64b793893d086f00fc72b4d7af"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('cumulusworkshop': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}